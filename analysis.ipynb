{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Analytics Assignment\n",
                "\n",
                "## 1. Environment Setup & Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mFailed to start the Kernel. \n",
                        "\u001b[1;31merror: failed-wheel-build-for-install\n",
                        "\u001b[1;31m\n",
                        "\u001b[1;31m× Failed to build installable wheels for some pyproject.toml based projects\n",
                        "\u001b[1;31m╰─> pyzmq. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', None)\n",
                "plt.style.use('ggplot')\n",
                "\n",
                "file_path = 'FJ Assignment - FJ Assignment - Sheet1(1).csv'\n",
                "try:\n",
                "    df = pd.read_csv(file_path)\n",
                "    print(f\"Loaded dataset with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
                "    display(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: File '{file_path}' not found. Please check the path.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Cleaning\n",
                "\n",
                "- **Charge**: Remove '$', ',' and convert to float.\n",
                "- **Weight**: Remove 'lbs' and convert to float.\n",
                "- **Zones**: Standardize to numeric (remove 'Zone ').\n",
                "- **Date**: Convert to datetime."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean 'Charge' column\n",
                "if df['Charge'].dtype == 'object':\n",
                "    df['Charge'] = df['Charge'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
                "    df['Charge'] = pd.to_numeric(df['Charge'], errors='coerce')\n",
                "\n",
                "# Clean 'Weight (lbs)' column\n",
                "if df['Weight (lbs)'].dtype == 'object':\n",
                "    df['Weight (lbs)'] = df['Weight (lbs)'].astype(str).str.lower().str.replace('lbs', '', regex=False).str.strip()\n",
                "    df['Weight (lbs)'] = pd.to_numeric(df['Weight (lbs)'], errors='coerce')\n",
                "\n",
                "# Clean 'Zones' column\n",
                "df['Zones'] = df['Zones'].astype(str).str.lower().str.replace('zone', '', regex=False).str.strip()\n",
                "df['Zones'] = pd.to_numeric(df['Zones'], errors='coerce')\n",
                "\n",
                "# Clean Date, handling errors\n",
                "df['Date of Delivery'] = pd.to_datetime(df['Date of Delivery'], errors='coerce')\n",
                "\n",
                "print(\"Data Types after cleaning:\")\n",
                "print(df.dtypes)\n",
                "\n",
                "# Date Analysis\n",
                "cutoff_date = pd.Timestamp('2025-01-01')\n",
                "df['Dataset_Type'] = df['Date of Delivery'].apply(lambda x: 'Future/Simulated' if x > cutoff_date else 'Historical')\n",
                "\n",
                "print(\"\\n--- Dataset Segmentation ---\")\n",
                "print(df['Dataset_Type'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Exploratory Data Analysis (EDA)\n",
                "\n",
                "### 3.1 Charge Types Distribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "df['Charge Type'].value_counts().head(20).plot(kind='barh')\n",
                "plt.title('Top 20 Charge Types')\n",
                "plt.xlabel('Count')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Cost Modeling & Aggregation\n",
                "\n",
                "### 4.1 Categorization Logic\n",
                "- **Base**: Core shipping cost ('Base Rate', 'Freight').\n",
                "- **Surcharge**: Mandatory fees (Fuel, Delivery Area, Residential).\n",
                "- **Penalty/Adjustment**: Avoidable costs or corrections (Address Correction, Late, Return).\n",
                "- **Other**: Anything else."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_charge(charge_type):\n",
                "    ct_lower = str(charge_type).lower()\n",
                "    \n",
                "    # Base\n",
                "    if ct_lower in ['base rate', 'freight']:\n",
                "        return 'Base'\n",
                "    \n",
                "    # Penalties / Adjustments\n",
                "    if any(x in ct_lower for x in ['correction', 'adjustment', 'penalty', 'late', 'return']):\n",
                "        return 'Penalty/Adjustment'\n",
                "    \n",
                "    # Surcharges (Default bucket for non-base, non-penalty)\n",
                "    return 'Surcharge'\n",
                "\n",
                "df['Category'] = df['Charge Type'].apply(classify_charge)\n",
                "\n",
                "# Check distribution\n",
                "print(df['Category'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Aggregation per Shipment\n",
                "We aggregate grouped by `Tracking Number` to get total shipment cost. We also retain `Dataset_Type` to compare Historical vs Future data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Aggregating\n",
                "aggregated = df.groupby(['Tracking Number', 'Carrier Name', 'Zones', 'Dataset_Type']).apply(\n",
                "    lambda x: pd.Series({\n",
                "        'Total_Cost': x['Charge'].sum(),\n",
                "        'Base_Cost': x[x['Category'] == 'Base']['Charge'].sum(),\n",
                "        'Surcharge_Cost': x[x['Category'] == 'Surcharge']['Charge'].sum(),\n",
                "        'Penalty_Cost': x[x['Category'] == 'Penalty/Adjustment']['Charge'].sum(),\n",
                "        'Num_Charges': len(x)\n",
                "    })\n",
                ").reset_index()\n",
                "\n",
                "aggregated['Has_Base_Rate'] = aggregated['Base_Cost'] > 0\n",
                "\n",
                "print(\"Shipment Summary Head:\")\n",
                "display(aggregated.head())\n",
                "\n",
                "# Check for Missing Base Rates in Historical Data\n",
                "historical_shipments = aggregated[aggregated['Dataset_Type'] == 'Historical']\n",
                "missing_base = historical_shipments[~historical_shipments['Has_Base_Rate']]\n",
                "print(f\"\\nHistorical Shipments: {len(historical_shipments)}\")\n",
                "print(f\"Historical Shipments missing Base Rate: {len(missing_base)}\")\n",
                "if len(missing_base) > 0:\n",
                "    print(\"Example Missing Base Rate:\", missing_base['Tracking Number'].iloc[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Normalized Comparison (Historical Data Only)\n",
                "For fair comparison, we focus on Historical Data where actual shipping patterns are observed. Future data appears to be simulated/uniform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(14, 6))\n",
                "sns.boxplot(x='Carrier Name', y='Total_Cost', hue='Zones', data=historical_shipments)\n",
                "plt.title('Historical Total Cost by Carrier and Zone')\n",
                "plt.legend(title='Zone', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
                "plt.xticks(rotation=45)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. \"Worst 10%\" Analysis\n",
                "\n",
                "We identify the 90th percentile of cost. We check if this is driven by specific carriers or charge types."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using ALL data for Worst 10% as requested (to catch potential future high costs)\n",
                "threshold_90 = aggregated['Total_Cost'].quantile(0.90)\n",
                "worst_10_df = aggregated[aggregated['Total_Cost'] >= threshold_90]\n",
                "\n",
                "print(f\"90th Percentile Threshold: ${threshold_90:.2f}\")\n",
                "print(f\"Number of Shipments in Worst 10%: {len(worst_10_df)}\")\n",
                "\n",
                "# Breakdown by Type\n",
                "print(\"\\nDataset Composition of Worst 10%:\")\n",
                "print(worst_10_df['Dataset_Type'].value_counts())\n",
                "\n",
                "# Drivers Analysis - Carrier\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(y='Carrier Name', data=worst_10_df, order=worst_10_df['Carrier Name'].value_counts().index)\n",
                "plt.title('Count of \"Worst 10%\" Shipments by Carrier')\n",
                "plt.show()\n",
                "\n",
                "# Drivers Analysis - Zone\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='Zones', data=worst_10_df)\n",
                "plt.title('Worst 10% by Zone')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Data Export\n",
                "\n",
                "Exporting the aggregated and cleaned dataset for external use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "output_file = 'processed_shipment_data.csv'\n",
                "aggregated.to_csv(output_file, index=False)\n",
                "print(f\"Processed data saved to {output_file}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
